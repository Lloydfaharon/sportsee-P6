import { NextResponse } from "next/server";
import jwt from "jsonwebtoken";

export async function POST(request: Request) {
  try {
    // ‚úÖ 1Ô∏è‚É£ R√©cup√®re le message ET l'ID utilisateur envoy√©s depuis le frontend
    const { message, userId } = await request.json();

    // --- D√©codage du token si userId manquant ---
    let finalUserId = userId;
    if (!finalUserId) {
      const cookieHeader = request.headers.get("cookie") || "";
      const tokenMatch = cookieHeader.match(/token=([^;]+)/);
      if (tokenMatch) {
        const token = tokenMatch[1];
        try {
          const decoded: any = jwt.decode(token);
          finalUserId = decoded?.userId;
          console.log("‚úÖ userId d√©tect√© depuis le token :", finalUserId);
        } catch (err) {
          console.warn("‚ùå Erreur lors du d√©codage du token :", err);
        }
      }
    }

    if (!finalUserId) {
      console.warn(
        "‚ö†Ô∏è Aucun userId re√ßu ni trouv√© dans le cookie. Mode test activ√©."
      );
    }

    // --- Validation basique ---
    if (!message || message.length > 500) {
      return NextResponse.json(
        { error: "Message invalide ou trop long." },
        { status: 400 }
      );
    }

    // --- 2Ô∏è‚É£ R√©cup√©ration des donn√©es utilisateur depuis ton API ---
    let userData = null;
    let perfData = null;

    try {
      // ‚úÖ Appelle ton endpoint Next.js local d√©j√† enrichi
      const userRes = await fetch(
        `${
          process.env.NEXT_PUBLIC_SITE_URL || "http://localhost:3000"
        }/api/user`,
        {
          headers: {
            Cookie: request.headers.get("cookie") || "",
          },
        }
      );

      if (userRes.ok) {
        userData = await userRes.json();
        perfData = userData?.performance || null;
      } else {
        console.warn(
          "‚ö†Ô∏è Impossible de r√©cup√©rer les donn√©es utilisateur :",
          await userRes.text()
        );
      }
    } catch (err) {
      console.warn(
        "‚ö†Ô∏è Erreur lors de la r√©cup√©ration des donn√©es utilisateur :",
        err
      );
    }
   
    //console.log("üì¶ Donn√©es r√©cup√©r√©es depuis /api/user :")
    //console.log("User:", userData);
    //console.log("Performance:", perfData);

    // --- Extraction des donn√©es utiles ---
    const userName = userData?.profile?.firstName || "utilisateur";
    const totalDistance = userData?.statistics?.totalDistance || "N/A";
    const totalSessions = userData?.statistics?.totalSessions || "N/A";
    const totalDuration = userData?.statistics?.totalDuration || "N/A";
    const userPhoto =
      userData?.profile?.profilePicture || "/images/default-avatar.jpg";

    // ---  Prompt syst√®me enrichi  ---
    const systemPrompt = `
Tu es Coach AI, l‚Äôassistant virtuel int√©gr√© √† l‚Äôapplication SportSee.

 Ton r√¥le :
Aider les utilisateurs √† comprendre et √† am√©liorer leurs performances sportives, leur r√©cup√©ration et leur nutrition.

 Ton comportement :
- Bienveillant, motivant et clair
- P√©dagogue mais jamais moralisateur
- Adapt√© au niveau de l‚Äôutilisateur : d√©butant, interm√©diaire ou expert
- Utilise un ton positif et professionnel
- √âvite le jargon, pr√©f√®re des explications simples
- Structure tes r√©ponses avec des listes, des paragraphes courts et parfois des emojis
- Ne fais jamais de diagnostic m√©dical : oriente vers un professionnel si n√©cessaire

Domaines couverts :
- Entra√Ænement (cardio, force, r√©cup√©ration, endurance)
- Nutrition et hydratation
- Pr√©vention et gestion des blessures
- Lecture des graphiques et indicateurs SportSee

Si la question sort du cadre du sport, r√©ponds :
‚ÄúJe suis ton coach sportif virtuel, concentrons-nous sur ton entra√Ænement üí™ !‚Äù

Exemple de style :
> Tr√®s bon r√©flexe 
> Essaie d‚Äôajouter une s√©ance de r√©cup√©ration active apr√®s chaque entra√Ænement intense.  
> Ton corps te remerciera demain 

====================
Donn√©es r√©elles de l'utilisateur :
- Pr√©nom : ${userName}
- Distance totale : ${totalDistance} km
- Nombre de sessions : ${totalSessions}
- Dur√©e totale : ${totalDuration} min
====================
`;

    // ---  D√©tection du type de question pour adapter la longueur de r√©ponse ---
    let maxTokens = 400; // valeur par d√©faut
    const lowerMsg = message.toLowerCase();

    if (
      lowerMsg.includes("programme") ||
      lowerMsg.includes("nutrition") ||
      lowerMsg.includes("aliment") ||
      lowerMsg.includes("planning") ||
      lowerMsg.includes("objectif") ||
      lowerMsg.includes("s√©ance") ||
      lowerMsg.includes("exercice")
    ) {
      maxTokens = 800; // r√©ponse longue pour programmes & conseils
    } else if (
      lowerMsg.includes("graphique") ||
      lowerMsg.includes("statistique")
    ) {
      maxTokens = 350;
    } else if (
      lowerMsg.includes("blessure") ||
      lowerMsg.includes("r√©cup√©ration")
    ) {
      maxTokens = 500;
    } else if (lowerMsg.includes("salut") || lowerMsg.includes("bonjour")) {
      maxTokens = 150;
    }

    console.log(`üß© max_tokens d√©fini sur : ${maxTokens}`);

    // --- Appel √† l‚ÄôAPI Mistral ---
    const res = await fetch("https://api.mistral.ai/v1/chat/completions", {
      method: "POST",
      headers: {
        Authorization: `Bearer ${process.env.MISTRAL_API_KEY}`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "mistral-medium-latest",
        messages: [
          { role: "system", content: systemPrompt },
          { role: "user", content: message },
        ],
        temperature: 0.5,
        max_tokens: maxTokens,
      }),
    });

    const data = await res.json();

    if (!res.ok) {
      console.error("Erreur Mistral:", data);

      //  Si la capacit√© du mod√®le est d√©pass√©e, on retente avec un mod√®le plus l√©ger
      if (
        data?.code === "3505" ||
        data?.message?.includes("capacity exceeded")
      ) {
        console.warn(
          "‚ö†Ô∏è Capacit√© du mod√®le d√©pass√©e ‚Äî nouvel essai avec mistral-small-latest..."
        );

        try {
          const retryRes = await fetch(
            "https://api.mistral.ai/v1/chat/completions",
            {
              method: "POST",
              headers: {
                Authorization: `Bearer ${process.env.MISTRAL_API_KEY}`,
                "Content-Type": "application/json",
              },
              body: JSON.stringify({
                model: "mistral-small-latest", 
                messages: [
                  { role: "system", content: systemPrompt },
                  { role: "user", content: message },
                ],
                temperature: 0.5,
                max_tokens: maxTokens,
              }),
            }
          );

          const retryData = await retryRes.json();

          if (retryRes.ok) {
            console.log(
              "‚úÖ R√©ponse obtenue via le fallback mistral-small-latest"
            );
            return NextResponse.json({
              reply:
                retryData.choices?.[0]?.message?.content || "Aucune r√©ponse.",
            });
          } else {
            console.error("‚ùå √âchec du fallback :", retryData);
          }
        } catch (retryError) {
          console.error("‚ùå Erreur lors du fallback Mistral :", retryError);
        }
      }

      return NextResponse.json(
        { error: "Erreur de communication avec Mistral" },
        { status: 500 }
      );
    }

    //  R√©ponse r√©ussie du premier appel
    return NextResponse.json({
      reply: data.choices?.[0]?.message?.content || "Aucune r√©ponse.",
    });
  } catch (error) {
    console.error(error);
    return NextResponse.json(
      { error: "Erreur serveur interne" },
      { status: 500 }
    );
  }
}
